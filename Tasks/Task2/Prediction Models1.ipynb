{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to select the attributes and prepare the data (remove outliers and data points with missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our initial analysis in the task 1 we know that we should use attributes like title bout, height, reach, stance, losing_streak, better rank and the label is 'Winner'. We can add more attributes later, but let's create the first models using only these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../data/ufc-master.csv')[['B_fighter', 'R_fighter', 'title_bout', 'B_current_lose_streak',\n",
    "       'R_current_lose_streak', 'B_Stance', 'R_Stance', 'B_age', 'R_age', 'height_dif', 'reach_dif', 'better_rank', 'Winner']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing mistakes in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 125)\n",
    "pd.set_option('display.max_columns', 125)\n",
    "#In the blue fighter stance column we have to fix one data point, where 'Switch' is written as 'Switch ' with an extra space\n",
    "#in the end\n",
    "data['B_Stance'] = data['B_Stance'].replace({'Switch ': 'Switch'})\n",
    "\n",
    "#In the height dif there is one outlier where the difference between the two fighters is 187.96 cm, which is obviously a mistake.\n",
    "#Instead of excluding this datapoint I am going to fix this manually using the height data available for both fighters on the\n",
    "#UFC website (the fighters were Parker Porter and Kyle Daukaus)\n",
    "data['height_dif'] = data['height_dif'].replace({-187.96: -7.62})\n",
    "data['height_dif'].value_counts()\n",
    "\n",
    "#In the reach difference we have 2 mistakes, where one of the values is -187.96 and the other is -160.02. These mistakes will be\n",
    "#fixed as well.\n",
    "#In the first case the fighters involved are Jinh Yu Frey and Kay Hanse\n",
    "#In the second case the fighters involved are Parker Porter vs Kyle Daukaus and Irwin Rivera vs Giga Chikadze\n",
    "filter1 = (data['reach_dif'] == -187.96) & (data['B_fighter'] == 'Parker Porter')\n",
    "filter2 = (data['reach_dif'] == -187.96) & (data['B_fighter'] == 'Irwin Rivera')\n",
    "filter3 = data['reach_dif'] == -160.02\n",
    "data[filter1] = data[filter1].replace({-187.96: -2.54})\n",
    "data[filter2] = data[filter2].replace({-187.96: -17.78 })\n",
    "data[filter3] = data[filter3].replace({-160.02: 5.08})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the most obvious errors are fixed in the dataset we have to turn categorical values into 1's and 0's and one-hot encode the other non-numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The values in the title_bout column were boolean\n",
    "data['title_bout'] = (data['title_bout']).astype(int)\n",
    "data['Winner'] = data['Winner'].map(dict(Blue=1, Red=0))\n",
    "data = pd.get_dummies(data, columns=['B_Stance', 'R_Stance', 'better_rank'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is ready. Let's split the data into training and validation set. Because the end goal is to use the model on predicting the fights that are not in the dataset we are not going to create a separate test set, but focus mainly on the training and validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are not going to use fighters names for prediction we are for the moment going to drop these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['B_fighter', 'R_fighter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(data.drop(columns='Winner'), data['Winner'], test_size = 0.15, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning and things like that will come later. First we want to identify algorithms that might do well.  \n",
    "\n",
    "Creating a simple decision tree classifier for the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5394932935916542\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "tree_1 = tree.DecisionTreeClassifier(criterion='gini', random_state = 0)\n",
    "tree_1.fit(X_train, y_train)\n",
    "accuracy_1 = accuracy_score(y_val, tree_1.predict(X_val))\n",
    "print(accuracy_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "54% accuracy is not the best start, but at least it is better than random guessing. Also at the end we will obviously train the chosen model on the entire dataset so we can expect better accuracy after that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now test a KNN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5201192250372578\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_1 = KNeighborsClassifier(n_neighbors = 1)\n",
    "knn_1.fit(X_train, y_train)\n",
    "accuracy_2 = accuracy_score(y_val, knn_1.predict(X_val))\n",
    "print(accuracy_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5439642324888226\n"
     ]
    }
   ],
   "source": [
    "knn_3 = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn_3.fit(X_train, y_train)\n",
    "accuracy_3 = accuracy_score(y_val, knn_3.predict(X_val))\n",
    "print(accuracy_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.533532041728763\n"
     ]
    }
   ],
   "source": [
    "knn_5 = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn_5.fit(X_train, y_train)\n",
    "accuracy_4 = accuracy_score(y_val, knn_5.predict(X_val))\n",
    "print(accuracy_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these simple test we can see that the KNN with the n value 3 did the best as it achieved 54.4% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5320417287630402\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_1 = RandomForestClassifier()\n",
    "forest_1.fit(X_train, y_train)\n",
    "accuracy_5 = accuracy_score(y_val, forest_1.predict(X_val))\n",
    "print(accuracy_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intial findings suggest that the KNN algorithm might be the best choice. Let's use a loop for finding the best comination of neighbors and metrics (Euclidean or Manhattan distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best achieved accuracy was: 58.42%.\n",
      "The neighbors value should be: 109\n",
      "The value for p should be: 2\n"
     ]
    }
   ],
   "source": [
    "#Note: in the KNN algorithm p=1 is Manhattan distance and p=2 is the Euclidean distance\n",
    "best_acc = 0\n",
    "best_comb = [0, 0]\n",
    "for i in range(1, 200, 1):\n",
    "    for j in range(1, 3, 1):\n",
    "        model = KNeighborsClassifier(n_neighbors = i, p = j)\n",
    "        model.fit(X_train, y_train)\n",
    "        acc = accuracy_score(y_val, model.predict(X_val))\n",
    "        if (acc > best_acc):\n",
    "            best_acc = acc\n",
    "            best_comb[0] = i\n",
    "            best_comb[1] = j\n",
    "print(\"The best achieved accuracy was: \" + str(round(best_acc * 100, 2)) + \"%.\")\n",
    "print(\"The neighbors value should be: \" + str(best_comb[0]))\n",
    "print(\"The value for p should be: \" + str(best_comb[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without using most of the attributes in the dataset we have already managed to get 58.4% accuracy on the validation set (validation set size is 15%), which is a rather promising sign."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
